%!TEX root = /Users/jp/Thesis/Thesis.tex
\chapter{Background} % (fold)
\label{cha:background}

\section{Definitions} % (fold)
\label{sec:definitions}

Before getting into deeper details about the project, it is important to clearly define some terms that will be used throughout this report.

\subsection{Web Service} % (fold)
\label{sub:web_service_def}

We think of Web Services in an abstract sense, as providers of content in response to a request, over the Internet. We assume that they can answer a precise query based on a set of defined conditions, and that they will return an ordered set of answers, the order being either based on a criteria provided by the user or by a relevancy score internal to the service. We can further take in consideration that the service has some performance rating, depending on the delay in which it returns the results as well as the quantity and quality of the results. Furthermore, we expect most web services to support some kind of pagination protocol in order to retrieve subsets of the data sequentially. Another important aspect of the services is that they might be subject to a monetary cost, or a limit in the querying rate, based on a daily period or otherwise.

For our purpose, the technology used for the transport and querying interface doesn't matter, be it SOAP, REST, Protobuffers or another binary or text encoding protocol. We assume that an adapter will be developed for each type of Web Service in order to use it.

% subsection web_service_def (end)

\subsection{Domain} % (fold)
\label{sub:domain_def}

A domain is a field of research as provided by one or more search engines. It could be, for example, international events, health professionals, countries information. In a query made by a user, a domain is characterized by the following parts:

\begin{itemize}

  \item One or more objects: While a domain represent an abstract entity, these are the concrete apparitions of the domain within the query. They may correspond directly to the name of the domain (eg. Give me a warm \emph{country}\ with cheap flights on the weekend of the first of may) or not (eg. Give me a \emph{conference}\ about computer science where I can also go to the opera, where conference is an object of the domain ``Event''). Additionally, more than one objects might refer to the same domain, in which case they need to be taken together.

  \item Conditions: Some conditions are given explicitly (eg. Give me a conference \emph{about computer science}.), while others can be deducted from the objects (\emph{conference}\ being a type of event). In general, conditions restrict the field of search that will be sent to the service. Some conditions are objective while others make use of subjective judgements (eg. \emph{warm}\ country).

  \item Ordering: Making the ranking and ordering according to some relevance score is an integral part of this project, and thus the ordering must be extracted and taken into account while answering a user's query. Again, some conditions can be subjective (the \emph{best}\ doctor in the region) while other elements can be taken both as a condition and as an implicit ordering ( \emph{cheap}\ flights will expose a cutoff in addition to the ordering by ascending price).

  \item One or more joins with other domains: at the core of this project is the presence of multiple domains within one query. These different domains must be joined in some way. These joins can be explicit, or inferred through a chain of relationships (an event is an city, that city is in a country) as expressed through a semantic network.

\end{itemize}


% subsection domain_def (end)

% section definitions (end)


\section{SeCo -- Search Computing} % (fold)
\label{sec:seco}

SeCo is the platform which aims to push the limits of the field of multi-domain queries by formalizing theoretical aspects as well as providing a software engineering point of view, enabling the construction of a usable search engine that will answer arbitrary queries.

\subsection{General Architecture} % (fold)
\label{sub:general_architecture}

SeCo is divided in different higher-level components orchestrated in a service-oriented manner. The main components are the query analysis, the query-to-domain mapper, the query planner, the query engine and the results transformation. Two frameworks named the service and domain frameworks are also added as intelligent repositories.

A query sent from the user first passes through the query analysis and the query-to-domain mapper, where the different domains and properties are extracted from the natural language query. It then goes to the query planner, which creates an execution plan taking into accounts the different costs associated to executing the query, in order to create the most efficient execution. The different subqueries are then sent to the domain and service frameworks, which take care of calling the external services through a Web or messaging interface. The results are then collected, and, according to the plan, merged back together. The final results are then transformed before being sent back to the user.

% subsection general_architecture (end)

\subsection{Query Analysis} % (fold)
\label{sub:query_analysis}

In order for a user to query the database of information and knowledge available in SeCo, he or she first needs to input it, whether by a Web interface, or by making a direct call to the programming interface of the system. The type of query the user gives can vary a lot, and it is for the system to try and understand the meaning of the question. In general, the contract of this component is to take the input as given by the user, try to separate it according to the sub-queries that can be found and send those down the line to the query planner.

% subsection query_analysis (end)

\subsection{Query to Domain Mapper} % (fold)
\label{sub:query_to_domain_mapper}

While the set of sub-queries is a first step towards actually executing the query, it still represents an abstract, human request that might or might not correspond to the the services available in the system. The Query to Domain Mapper will take each sub-query in turn, and corresponding to the vocabulary used and the elements in the query, will try to associate a domain as stored in the domain framework. It will send this augmented request to the next component, the query planner.

% subsection query_to_domain_mapper (end)

\subsection{Query Planner} % (fold)
\label{sub:query_planner}

The Query Planner's task is to take the set of high-level queries to different domains and turn it into an executable plan. This involves planning the fetching of data to web services, taking into account the frequency and quantity of data that will be required, and the merge operations that will be done, all in order to minimize the time and memory spent, as well as any costs related to the user of the web services.

This plan is now ready to be executed by the query engine as it contains precise instructions on what to execute and in which order. It is comparable to having taken a declarative program as input and obtaining an imperative program that can be run directly.

% subsection query_planner (end)

\subsection{Query Engine} % (fold)
\label{sub:query_engine}
This component takes the low-level plan from the query planner and executes the different service calls in parallel, merging and ordering when required. It will return the final results of the query in a pure and internal format as they become available, sending them to the results transformation component for their final processing.

Care must be taken in accord to the availability and performance of the invoked services. Since there is an heavy reliance on external components, failures or low performance problems will be common and will have to be considered while fetching the results.
% subsection query_engine (end)

\subsection{Results Transformation} % (fold)
\label{sub:results_transformation}
This component's role is to take the results as given by the Query Engine, and to transform and format them in the way that was required by the client. It implements features such as paging, XML or XHTML output.
% subsection results_transformation (end)

% section seco (end)

\section{Sources of Input Data} % (fold)
\label{sec:sources_of_input_data}

In order to get some interesting results and also to test the validity of our approach, a corpus of example data was required. Given the originality of the project, there was no available corpus that is both already filtered and annotated according to our needs. While there are corpora that include single-domain tagging, or simple text annotations, none were specific enough to include multi-domain questions highlighted with the parts of the sentences that correspond to diverse domains and that include the domains related to each question.

We thus had to go find a large and open source of questions that could possibly be asked by end users and that could eventually be automatically translated into the format needed by the query engine. One such source was found to be Yahoo! Answers, a service where users can input their questions about diverse subjects and have other users directly and personally answer. While they do not give a complete access to their corpus, they provide, free of charge, a Web application programming interface that allows the gradual extraction of the questions.

Questions in Yahoo! Answers are organized in categories representing different areas of human interests, like technology, spirituality, family matters. In a first pass, we surveyed many of these categories, but we found the \emph{tourism}\ category to contain the overwhelming majority of interesting questions, and thus it was decided to take it as the sole sample, as the others categories had a very low signal to noise ratio.

This brings us to the problem of filtering this data. Given that it is undirected, almost random, user input, the quality of the questions asked was varying. This quality we are looking for in a question is quite abstract and thus has had in a first pass to be decided by a human being. The criteria we apply to the filtering of the questions were manifold. The first one was a rough judgement of the quality of the English; while we cannot expect users to write perfect English, the tools we use in the processing chain are based on annotations of published text and thus are not trained on mistaken input. In the engineering phase, we can hope to expand the training of the data to include malformed sentences.

Furthermore, it is to be understood that users of Yahoo! Answers get to divide their question into two different input fields, a first one containing a brief question, as well as a longer and more descriptive version of their asking. For the sake of brevity and to represent a typical question that will be input in the prototypical search box, we decided to take only the smaller version of the question as our input. As such, we also need to remove entries where user chose to input meaningless or generic data in the summary (e.g. ``Help please!'').

The final and most elusive criterion is the presence of a multi-domain aspect to the question. It is arguable, but it could be assumed that most users, trained for years by the mainstream search engines to ask very precise questions in order to get somewhat relevant results, are now used to ask questions in a single-domain manner, then trying to make the links themselves, even when they do ask other users. It is thus difficult to extract true multi-domain questions from the existing corpus. Furthermore, while a multi-domain question is clearly defined in terms of querying more than one service, the quality of a question to span more than one domain from the point of view of natural language is fuzzier. In particular, the difference between a single-domain question accompanied by a complex condition or a true multi-domain question can at times be confusing.

To compound these diverse problems, we went from a simple yes/no filtering scheme to a more complex range of rating, where an entry is annotated with a single score which can range from 1 to 5, giving us some flexibility in organizing the results, as well as covering more possible input cases than could be extracted previously.

While this concludes the discussion on our main source of input data, further sources were used. The first of these is WordNet, the most comprehensive lexical database available to use. It consists of a library of words, organized by their grammatical roles, such as nouns, adjectives, verbs, adverbs, and which contains the various senses a word could possibly employ, as well as its various synonyms. It thus presents an interesting compound between a dictionary and a thesaurus, making it especially applicable to text analysis and artificial intelligence.

In addition to the simple definitions, WordNet presents a view of a semantic network between words. Example annotations for nouns are hypernyms (Y is an hypernym of X if X is a kind of Y, e.g. \emph{bird}\ is an hypernym of \emph{canary}) or hyponyms (the opposite relationship).

The database represents more than a hundred and fifty thousand words that have been extracted from published texts and manually annotated. It is thus an impressively large corpus that can present many applications.

On top of the WordNet database, another project called WordNet Domains has taken root, adding a new way of organizing the information found within the library. Taking as base the Dewey Index, the creating team at the Fondazione Bruno Kessler has assigned one or more domain to each synonymous set or sense a word can take, organizing the whole WordNet corpus in around 200 categories that represent human interests.
% section sources_of_input_data (end)

\section{Query Analysis} % (fold)
\label{sec:query_analysis}

In general, we consider Query Analysis to encompass the set of techniques that allow a program to translate an input question into a form that can be acted upon by an information retrieval program, be it a relational database or a complex question-answering system like SeCo.

In particular, the input can be presented in many forms. The first and simplest of these is to require a completely formal and structured syntax, such as the case of SQL. In this case, a parser for a context-free grammar can formally translate the input or outright reject it without any doubt to the result of the query. Of course, in that case, the burden is put upon the end user to enter a valid query as the analysis is strict. While this presents many advantages in the realms of consistency and reliability, it is often an impossible task a user to comply with, which makes it impractical for an end-user application.

The opposite to this previous representation is to allow a free form input to take place, accepting liberally and trying to make sense of it. This moves the burden from the user to the computer program who has to accept a dizzying range of possible inputs, with possible grammatical mistakes, strange constructions or unclear demands. Even then, there are many possible levels in which the query can be analyzed.

The most widely used model today is to take the input from the user as a simple bag of words, discarding the parts that present little differentiating power or that are not understood. This is a simple approach that works well when a simple match between the keywords and the results can made, for example in the field of document retrieval, where the presence of the words in a document is a good indicator of its relevance and should award its presence in the results.

While this is an interesting approach that warrants good results, it is limited by its simplicity, as it does not allow to understand the full expression of the language. Links between words and parts of the sentence are ignored, and the structure of the sentence, which in many cases can be quite revealing, is flattened into a single level.

While, in the end, some flattening must take place to reduce the question to a simpler representation, advanced techniques allow to make this procedure in a more intelligent fashion, and make use of the general category of tools that can be grouped under the term \emph{Natural Language Processing}.

\subsection{Natural Language Processing} % (fold)
\label{sub:natural_language_processing}

This set of techniques and sciences takes it name from natural languages, under which we group all the human languages, such as English, Italian, Chinese, and which we distinguish from the formal and simplistic languages used to instruct a computer, like C++, Java.

This is a domain of very active research in which many challenges still reside. The main problems that a tool in this realm faces are that the languages we speak and write make use of highly contextual and ambiguous syntaxes, for which the usual computer language processing tools are direly unadapted.

The basic techniques are about annotating each part of the input with various categorizations, and then organize these tokens into complex structures. One first categorization is part-of-speech tagging, where each word in the sentence is attributed its grammatical role, that is, verb, noun, adjective, adverb or other. Another is word sense disambiguation, where the sense of a word is selected from many possibilities using the context around the word.

A second and more convoluted pass is to make sense of the whole sentence, that is, to give it a structure. This structure, which we can call a parse tree, can then be used to extract the meaning of the sentence and it is what we use to try to translate the user input into a form that can be acted upon by the search engine.

% subsection natural_language_processing (end)

\subsection{Parts of a Sentence} % (fold)
\label{sub:parts_of_a_sentence}

Prior to explaining the complete structures of the parse trees obtained from the natural language processing tools, it is important to define what elements are considered the atoms and groups of a sentence.

Going from a top-down approach, the central element of an input in the sentence. While there is typically only one sentence in an entry, a user could enter a complex query that takes place over two sentences, in which case a clear division will be made.

The most important following constructions and the core of the sentences are the noun phrases and the verb phrases. The noun phrases center around one or more (in the case of collocations) noun atoms, which can specifically be common or not, and singular or plural. It is accompanied by its articles, adjectives and in some cases, adverbs to those adjectives. The nouns phrases can act as subjects, direct or indirect objects. Instead, the verb phrases correspond to the verb itself, which can consist of auxiliaries such as \emph{have}, \emph{be}, \emph{can}, \emph{will} or the single action verb, and which can be associated with one or more adverbs. The complements to the verb are typically attached within the verb phrase.

Other frequent compound structures are the relative and subordinate clauses, which correspond to sub-sentences in the phrase linked to the rest by a preposition such as \emph{that}, \emph{which}\ or a conjunction. From this category, one particular kind of clause is of particular important to us, the clause introduced with a \emph{wh-word}, such as \emph{where}, \emph{who}, \emph{what}, \emph{which}, as they represent more often than not questions, which is exactly what we are looking for

The building atoms of a sentence are the nouns, the verbs, the adverbs, the adjectives, the determinants, the prepositions, the conjunctions as well as the punctuation.

You may refer to table~\ref{penntree_symbols} for a brief overview of the most commonly used parts of the sentences, either atoms or groupings, with their symbol in the standardized Penn Treebrank format. This format is the one that is used consistently by the parsers to annotate and structure a sentence, and that has been used to manually annotate the sentences used by said parsers as training data.

\begin{table}[ht]
  \caption{Elements of a sentence and their symbol}
  \label{penntree_symbols}
  \begin{center}
  \begin{tabular}{r l}
  Element & Symbol\\
  \hline
  Sentence & S\\
  Relative clause & SBAR\\
  Subordinate clause & SBAR\\
  Relative clause (question) & SBARQ\\
  Noun Phrase & NP\\
  Common noun (singular) & NN\\
  Common noun (plural) & NNS\\
  Proper noun (singular) & NNP\\
  Proper noun (plural) & NNPS\\
  Verb Phrase & VP\\
  Verb, base form & VB\\
  Verb, past tense & VBD\\
  Verb, present & VBP or VBZ\\
  Adjective & JJ\\
  Adverb phrase & ADVP\\
  Adverb & RB\\
  Article, determiner & DT\\
  Personal pronoun & PRP\\
  Preposition & IN\\
  \emph{to} & TO\\
  Conjunction & CC\\
  Punctuation & . or ?\\
  \end{tabular}
  \end{center}
\end{table}

% subsection parts_of_a_sentence (end)

\subsection{Parse Trees} % (fold)
\label{sub:parse_trees}

Parse Trees are at the core of the techniques used in this project, and thus merit a deeper look. As explained previously, they are the results of the parsing done at the previous level by the various tools. They are generated by the parsers by using a probabilistic algorithm that has been trained by a large corpus of sentences that have been annotated by hand. The parser, then compares the sentence to its bank and produce the most probable structures that correspond to a sentence, of which we usually take the top one.

What results from the parsing is a tree, where internal nodes represent a structure, a grouping of words that represent some interesting part of the sentence, while the leaves are the words themselves, tagged with their respective part of speech. Refer to section~\ref{sub:parts_of_a_sentence} for the details of the symbols and their meanings.

For example, consider the following input: ``The strongest rain ever recorded in India shut down the financial hub of Mumbai, snapped communication lines, closed airports and forced thousands of people to sleep in their offices or walk home during the night, officials said today.''

Here is the resulting tree, shown here with parentheses outlining the structure.
\begin{verbatim}
  (ROOT
    (S
      (S
        (NP
          (NP (DT The) (JJS strongest) (NN rain))
          (VP
            (ADVP (RB ever))
            (VBN recorded)
            (PP (IN in)
              (NP (NNP India)))))
        (VP
          (VP (VBD shut)
            (PRT (RP down))
            (NP
              (NP (DT the) (JJ financial) (NN hub))
              (PP (IN of)
                (NP (NNP Mumbai)))))
          (, ,)
          (VP (VBD snapped)
            (NP (NN communication) (NNS lines)))
          (, ,)
          (VP (VBD closed)
            (NP (NNS airports)))
          (CC and)
          (VP (VBD forced)
            (NP
              (NP (NNS thousands))
              (PP (IN of)
                (NP (NNS people))))
            (S
              (VP (TO to)
                (VP
                  (VP (VB sleep)
                    (PP (IN in)
                      (NP (PRP$ their) (NNS offices))))
                  (CC or)
                  (VP (VB walk)
                    (NP (NN home))
                    (PP (IN during)
                      (NP (DT the) (NN night))))))))))
      (, ,)
      (NP (NNS officials))
      (VP (VBD said)
        (NP-TMP (NN today)))
      (. .)))
\end{verbatim}

We can see the main features of any parsed sentences, that is, a top level ROOT element, followed by one or more sentence, which encloses a series of noun phrases and verb phrases that can be arbitrarily nested. Inside the phrases, the core objects can be found, accompanied by their objects, prepositions and others. Here, the first noun phrase corresponds to the main subject of the sentence, and it is followed by a verb phrase, which in this case consists of a series of nested verb phrases, one for each action in the sentence. Each verb phrases has it own object

% subsection parse_trees (end)

% section query_analysis (end)

\section{Use of Query Analysis within SeCo} % (fold)
\label{sec:use_of_query_analysis_within_seco}

The Search Computing project aims to reach a new level within the worlds of search engines and question-answering expert systems, allowing to link previously difficult to access data bases in new and interesting ways. The project has seen great progress in hiding most of this complexity away from the users. A critical part of this interfacing between end users and the system itself is to get the user to input its query in the most natural way possible.

Getting back to the original vision of the problem, we see that the project aims to help users answer questions, questions which were previously tedious to search for, both because they required access to opaque services, as well as a lot of manual work to coordinate the answers from the various services in a reasonable manner. Given that we want now to answer these questions for the user, it makes sense to take as input the question itself as it has been formulated by a user, and give the best answer given the system's access to external services which can provide parts of the answers.

In this fashion, query analysis is required to translate the question from the natural way a user would input it, into a form the system can understand and act upon. Most primordially, it is necessary to use query analysis to understand which domains are put into play within the question, leading the system to choose the corresponding services.

% section use_of_query_analysis_within_seco (end)

\section{Originality} % (fold)
\label{sec:originality}

While much progress has been done in the field of expert or question-answering systems, they mostly limit themselves to either a single topic or a very simple, unnatural syntax. This simplifies the problem greatly, but it still moves the burden of getting interesting results from the system, where it should be, to the user, who now has to put great effort in getting the system to understand him.

Furthermore, existing projects usually take a bottom-up approach, where the data is organized and a service is offered to access it in diverse fashions, and where the input possibilities are dictated by the shape and organization of the data model. On the other hand, ours is following a top-down methodology, taking as base the input of the user, and try to extract meaning from it. This is both required by the great variety and variability that is found in the interacting services, as well as desirable from a point of view, as it will provide a much easier access to complex queries, queries that would have taken pages of declarative queries using previous approaches.

% section originality (end)

% chapter background (end)
