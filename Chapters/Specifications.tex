%!TEX root = /Users/jp/Thesis/Thesis.tex
\chapter{The Natural Language Query Analysis and Evaluation Process} % (fold)
\label{cha:specifications}

Given the originality of the present project, research had to be done in order to find an optimal approach to extracting domains from a typical user input. In this chapter, we will explain the methodology employed to find out such an approach, as well as the tools that were created to reach this purpose.

\section{Methodology} % (fold)
\label{sec:methodology}

To get interesting results from this experiment, a formal methodology was needed. While it is quite simple, it provides us with great flexibility and with constant progress towards the goal of extracting domains from a simple request. This project has two major phases, which shall be described further in details and of which an overview in available in figure~\ref{fig:methodology}. In the first phase, a corpus that responds to the needs of the project, that is, assembled of as many multi-domain queries as possible, has to created from scratch using publicly available data, as well as some manually-entered ones.

In a second phase, from this larger corpus, a smaller but most interesting section is taken and analyzed in depth. Again this analysis has two aspects. The first one is to find a technique that will allow us to split a question in the diverse domains that constitute it, and extract the important objects from those parts. The second one is to take the resulting objects, and associate them with one or more semantical domain of knowledge that will be mapped to the corresponding services. For both these problems, various approaches will be developed and evaluated, individually and relatively to each other.

\begin{figure}[ht!]
  \begin{center}
    \includegraphics[width=\linewidth]{images/methodology}
  \end{center}
  \caption{High-level Methodology}\label{fig:methodology}
\end{figure}

% section methodology (end)

\section{Creation of the corpus} % (fold)
\label{sec:creation_of_the_corpus}

\subsection{Data Extraction} % (fold)
\label{sub:data_extraction}

The first step towards achieving our goal is to obtain an interesting and sizable corpus of data to analyze and on which we can try different algorithms. In order to do this, we used the previously explained choice of Yahoo! Answers, querying it to slowly build a collection of typical user entries.

% subsection data_extraction (end)

\subsection{Entry filtering \amper\ rating} % (fold)
\label{sub:entry_filtering_rating}

Of course, these questions were entered by human beings for the benefit of other human beings, and while they have to be clear enough to be understood by others, no concern has been put in making them clear enough for a computer system to understand them. Thus, a lot of the entries obtained in the previous phase are lacking in content, in clarity or contain too many grammatical errors to consider them as valid entries. They have to be filtered out, or at least flagged as of little importance to our research.

Similarly, we focus our attention on the multi-domain questions, and this is this aspect that we want to characterize in the corpus. We must thus highlight the entries that present this quality. The procedure we use to do that is to give them a rating that go from one, where an entry is useless or of no importance, to five, where an entry represents an excellent subject for research.

This manual rating also presents an excellent opportunity for successive phases in which we can try to use the existing data as training data to try to see if we can automatically sort new entries in the good classification.

% subsection entry_filtering_rating (end)

% section creation_of_the_corpus (end)

\section{Query Analysis} % (fold)
\label{sec:query_analysis_spec}

\subsection{Parsing} % (fold)
\label{sub:parsing}

% subsection parsing (end)

\subsection{Extraction strategies} % (fold)
\label{sub:extraction_strategies}

% subsection extraction_strategies (end)

\subsection{Domain Mapping Strategies} % (fold)
\label{sub:domain_mapping_strategies}

% subsection domain_mapping_strategies (end)

\subsection{Results evaluation} % (fold)
\label{sub:results_evaluation}

% subsection results_evaluation (end)

% section query_analysis_spec (end)

\section{Data Models} % (fold)
\label{sec:data_models}
Different data models are used in the components, both internally and externally. The ones interesting for this research correspond to the ones that will be given as inputs and outputs to the different components and that will allow us to interact with those components.

The Query Analysis component will require two data models; The high-level query is its main input, while it outputs principally an abstract low-level query. The Query-to-domain Mapper will take that abstract query, and replace it with a concrete low-level query. The Domain Framework will make use of the additional data model that is the Domain Descriptor.

\subsection{High-level Query} % (fold)
\label{sub:high_level_query}

A high-level query is given as input to the query analysis, and is for the most part the direct input of the user. It will be given in the form of a quasi-natural question. It can optionally be augmented with some hints that will be in the form of Google Search's keywords, such as "ranking: temperature" or "domain: conference". Internally, this high-level query will be taken as a single string of arbitrary length.

% subsection high_level_query (end)

\subsection{Low-level Query} % (fold)
\label{sub:low_level_query}

A low-level query, either in the abstract or concrete form, will be given in a datalog-like format, that is, as a set of logical predicates describing the properties of diverse objects. These predicates will allow the use of constants, which will define restrictions on the properties of the desired outputs, as well as variables, which will roughly be in a similar amount to the number of different domains that can be extracted from the query. Extensions to the format include complex boolean logic, as well as special predicates that will control the ranking.  Following is an example low-level query, where an uppercase symbol denote a variable and a lowercase one a constant. The associated high-level query for this would be "Give me a conference about computer science in a country where the average temperature is higher than 20 degrees".

\begin{verbatim}
  type(X, conference).
  type(Y, country).
  topic(X, computer science).
  country(X, Y).
  average_temperature(Y, > 20).
\end{verbatim}

Additionally, such a query can be made concrete by annotating it with the corresponding domains, as well as the services that will be needed during the execution of the query, making it into the following example.

\begin{verbatim}
  type(X, conference).
  type(Y, country).
  topic(X, computer science).
  country(X, Y).
  average_temperature(Y, > 20).
  
  domain(X, events).
  domain(Y, country).
  service(X, service_ref(123)).
  service(Y, service_ref(456)).
\end{verbatim}

It is important to note the difference between the type of the object and its domain. In our case, we can see that the Y object share the same type and domain. On the other hand, the X object, of type conference, will be deducted to be an element of the query domain of events. The object in that case becomes a predicate that will restrict the field of search on this particular generic domain.

% subsection low_level_query (end)

\subsection{Domain} % (fold)
\label{sub:domain}

For the purposes of our research, a domain will be simply considered as a mapping between a unique name (eg. Event) and a series of keywords organized either as a simple bag, as an ontology or a taxonomy. It will also contain the different services that can be used to answer a query that corresponds to the selected domain.
% subsection domain (end)

% section data_models (end)

\section{Interfaces} % (fold)
\label{sec:interfaces}

While the components are organized in a chain corresponding to the flow of information in the system, they will be mostly independent from one another, that is, the components will not call directly their successor to continue the execution. Instead, they will be organized in a service fashion, where they will only respond to a request by sending back a response to the client. The client in the main case will be an orchestrator that will take into account each component, calling them in turn and validating the output after each step, taking care of error and exception checking, as well as interaction with the end user through an HTTP or graphical interface.

Thus, each component will be defined individually in regards to its external interface, although one component might make use of another component internally (for example, the Query-to-Domain Mapper will use the Domain Framework).

\subsection{Query Analysis} % (fold)
\label{sub:query_analysis_dm}

The query analysis will respond to a very simple interface. It consists of one method that takes a high-level query as given by a user and outputs a series of abstract low-level queries as presented earlier. These low-level queries will be wrapped in a result object that allow the component to give additional information such as the things it ignored or could not understand, the errors it encountered, which might be useful to help the user refine its search.

\begin{verbatim}
  type result = { annotations: string[], queries: lowLevelQuery[]}
  analyzeQuery(highLevelQuery: string): result
\end{verbatim}

% subsection query_analysis_dm (end)

\subsection{Query to Domain Mapper} % (fold)
\label{sub:query_to_domain_mapper_int}

The query to domain mapper will also follow a simple contract, that is, of taking the abstract low-level queries given directly or transformed from a high-level query through the query analysis, and making them concrete, that is associating the domain and the web service to call to each individual low-level query.

\begin{verbatim}
  mapDomain(queries: lowLevelQuery[]): lowLevelQuery[]
\end{verbatim}

% subsection query_to_domain_mapper_int (end)

\subsection{Domain Framework} % (fold)
\label{sub:domain_framework}

For the purpose of this thesis, the only interfaces that will be needed to use the domain framework will be the ones that allow us to associate a domain from a query object, as well as the one that will help us find a service from a pre-selected domain. To obtain the domain, we will want to give the framework the object we consider at the center of the domain query (eg. \emph{conference}\ in ``give me a conference about computer science...''), as well as the sentence fragment to help the framework disambiguate on certain cases. It will return the most likely domain associated with that object, or None if it can't find anything that could be used.

\begin{verbatim}
  type domain = int // a domain is identified by an integer
  findDomain(object: string, fragment: string): domain
\end{verbatim}

The second interface takes the domain and the queries and will return the best service to use considering the conditions in the query. Some services will take different parameters, and so, depending on the conditions that are requested in the query, a different service might be called. This is why we include the query in the search for a proper service.

\begin{verbatim}
  type service = int // a service is also identified by an integer
  getServiceFromDomain(aDomain: domain, query: lowLevelQuery[]): service
\end{verbatim}

% subsection domain_framework (end)

% section interfaces (end)


% chapter specifications (end)